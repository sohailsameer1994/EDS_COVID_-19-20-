{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Your base path is at: ads_covid-20'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## check some parameters\n",
    "## depending where you launch your notebook, the relative path might not work\n",
    "## you should start the notebook server from your base path\n",
    "## when opening the notebook, typically your path will be ../ads_covid-19/notebooks\n",
    "import os\n",
    "if os.path.split(os.getcwd())[-1]=='notebooks':\n",
    "    os.chdir(\"../\")\n",
    "\n",
    "'Your base path is at: '+os.path.split(os.getcwd())[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Update all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error : b''\n",
      "out : b'Already up to date.\\n'\n",
      " Number of regions rows: 412\n"
     ]
    }
   ],
   "source": [
    "# %load src/data/get_data.py\n",
    "\n",
    "\n",
    "import subprocess\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "import requests\n",
    "import json\n",
    "\n",
    "def get_johns_hopkins():\n",
    "    ''' Get data by a git pull request, the source code has to be pulled first\n",
    "        Result is stored in the predifined csv structure\n",
    "    '''\n",
    "    git_pull = subprocess.Popen([\"git\", \"pull\"], #\"/usr/bin/git pull\" ,\n",
    "                        cwd = os.path.dirname(\"C:/Users/sohai/Videos/Python/ads_covid-20/data/raw/COVID-19/\"),\n",
    "                        shell = True,\n",
    "                        stdout = subprocess.PIPE,\n",
    "                        stderr = subprocess.PIPE )\n",
    "    (out, error) = git_pull.communicate()\n",
    "    print(\"Error : \" + str(error)) \n",
    "    print(\"out : \" + str(out))\n",
    "\n",
    "\n",
    "\n",
    "def get_current_data_germany():\n",
    "    ''' Get current data from germany, attention API endpoint not too stable\n",
    "        Result data frame is stored as pd.DataFrame\n",
    "\n",
    "    '''\n",
    "    \n",
    "    data=requests.get('https://services7.arcgis.com/mOBPykOjAyBO2ZKk/arcgis/rest/services/RKI_Landkreisdaten/FeatureServer/0/query?where=1%3D1&outFields=*&outSR=4326&f=json')\n",
    "\n",
    "    json_object=json.loads(data.content)\n",
    "    full_list=[]\n",
    "    for pos,each_dict in enumerate (json_object['features'][:]):\n",
    "        full_list.append(each_dict['attributes'])\n",
    "\n",
    "    pd_full_list=pd.DataFrame(full_list)\n",
    "    pd_full_list.to_csv('data/raw/NPGEO/GER_state_data.csv',sep=';') #storing the data to csv file\n",
    "    print(' Number of regions rows: '+str(pd_full_list.shape[0]))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    get_johns_hopkins()\n",
    "    get_current_data_germany()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Process pipeline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Number of rows stored: 236\n",
      " Number of rows stored: 62776\n",
      " Latest date is: 2020-09-13 00:00:00\n",
      "222 countries population information stored: \n"
     ]
    }
   ],
   "source": [
    "# %load src/data/process_JH_data.py\n",
    "# %load src/data/process_JH_data.py\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "def store_flat_data():\n",
    "    data_path='data/raw/COVID-19/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv'\n",
    "    DF_raw=pd.read_csv(data_path)\n",
    "    EDA_Full_data=pd.DataFrame(np.array(DF_raw.columns[4:]), columns=['Date']) # converting the present dataframe into more readable and easily plotable dataframe\n",
    "    allcountries= list (DF_raw['Country/Region'].unique())\n",
    "\n",
    "    for each in allcountries:\n",
    "        EDA_Full_data[each]= np.array(DF_raw[DF_raw['Country/Region']== each].iloc[:,4::].sum())\n",
    "\n",
    "\n",
    "    time_idx=[datetime.strptime( each,\"%m/%d/%y\") for each in EDA_Full_data.Date] # convert to datetime\n",
    "    time_str=[each.strftime('%Y-%m-%d') for each in time_idx] # convert back to date ISO norm (str)\n",
    "    EDA_Full_data['Date']= time_idx\n",
    "    EDA_Full_data.to_csv('data/processed/COVID_full_flat_table.csv',sep=';',index=False)\n",
    "    print(' Number of rows stored: '+str(EDA_Full_data.shape[0]))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def store_relational_JH_data():\n",
    "    \n",
    "    ''' Transformes the COVID data into a  relational data set which can be used for modeling \n",
    "\n",
    "    '''\n",
    "\n",
    "    path='data/raw/COVID-19/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv'\n",
    "    raw_data = pd.read_csv(path)\n",
    "\n",
    "    base_df =raw_data.rename(columns={'Country/Region':'country',\n",
    "                      'Province/State':'state'})\n",
    "\n",
    "    base_df['state']=base_df['state'].fillna('no')\n",
    "\n",
    "    base_df=base_df.drop(['Lat','Long'],axis=1)\n",
    "\n",
    "\n",
    "    pd_relational_model=base_df.set_index(['state','country']) \\\n",
    "                                .T                              \\\n",
    "                                .stack(level=[0,1])             \\\n",
    "                                .reset_index()                  \\\n",
    "                                .rename(columns={'level_0':'date',\n",
    "                                                   0:'confirmed'},\n",
    "                                                  )\n",
    "\n",
    "    pd_relational_model['date']=pd_relational_model.date.astype('datetime64[ns]')\n",
    "\n",
    "    pd_relational_model.to_csv('data/processed/COVID_relational_confirmed.csv',sep=';',index=False)\n",
    "    print(' Number of rows stored: '+str(pd_relational_model.shape[0]))\n",
    "    print(' Latest date is: '+str(max(pd_relational_model.date)))\n",
    "\n",
    "def store_population_data():\n",
    "    ''' Transformes the Population data to a required form and matching data to covid data\n",
    "\n",
    "    '''\n",
    "\n",
    "    df_pop=pd.read_csv('data/raw/Data_Extract_From_World_Development_Indicators/Population.csv ')\n",
    "    df_P= df_pop[['Country Name', '2019 [YR2019]']] #considering latest population\n",
    "    df_P=df_P.rename(columns={'Country Name':'country',\n",
    "                             '2019 [YR2019]':'population'})\n",
    "    df_P = df_P.iloc[0:217,:] # as we hust need distinct countries\n",
    "    df_P['country'] = df_P['country'].replace(['Bahamas, The', 'Brunei Darussalam', 'Myanmar','Congo, Dem. Rep.',\n",
    "                                       'Congo, Rep.','Czech Republic','Egypt, Arab Rep.','Gambia, The','Iran, Islamic Rep.','Korea, Rep.',\n",
    "                                      'Kyrgyz Republic','Lao PDR', 'Russian Federation','St. Kitts and Nevis','St. Lucia','St. Vincent and the Grenadines',\n",
    "                                      'Slovak Republic', 'Syrian Arab Republic','United States','Venezuela, RB','Yemen, Rep.'],\n",
    "                                      ['Bahamas','Brunei','Burma','Congo (Brazzaville)','Congo (Kinshasa)','Czechia','Egypt',\n",
    "                                       'Gambia','Iran','Korea, South', 'Kyrgyzstan', 'Laos', 'Russia', 'Saint Kitts and Nevis',\n",
    "                                        'Saint Lucia', 'Saint Vincent and the Grenadines', 'Slovakia', 'Syria', 'US',\n",
    "                                       'Venezuela', 'Yemen'])\n",
    "    df_P['population'] = df_P['population'].replace('..',3214000)\n",
    "    df_P2 = pd.DataFrame([['Diamond Princess', 2670], ['Holy See', 825],['MS Zaandam', 1432],['Taiwan', 23780000],['Western Sahara',652271]], columns=['country', 'population'])\n",
    "    df_P=df_P.append(df_P2, ignore_index=True) # Adding additional countries\n",
    "    df_P['population']=df_P.population.astype(int)\n",
    "    df_P.to_csv('data/processed/world_population.csv',sep=';',index=False)\n",
    "    print(str(df_P.shape[0])+ ' countries population information stored: ')\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    store_flat_data()\n",
    "    store_relational_JH_data()\n",
    "    store_population_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3  Filter and Doubling Rate Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the test slope is: [2.]\n",
      "            date state country  confirmed  confirmed_filtered  confirmed_DR  \\\n",
      "37283 2020-09-09    no   India  4465863.0           4467762.2     47.153948   \n",
      "37284 2020-09-10    no   India  4562414.0           4562549.0     46.453044   \n",
      "37285 2020-09-11    no   India  4659984.0           4657808.8     47.009377   \n",
      "37286 2020-09-12    no   India  4754356.0           4753115.8     48.545060   \n",
      "37287 2020-09-13    no   India  4846427.0           4848422.8     50.992411   \n",
      "\n",
      "       confirmed_filtered_DR  \n",
      "37283              48.421074  \n",
      "37284              48.089699  \n",
      "37285              48.016714  \n",
      "37286              48.883904  \n",
      "37287              49.871634  \n"
     ]
    }
   ],
   "source": [
    "# %load src/features/build_features.py\n",
    "\n",
    "import numpy as np\n",
    "from sklearn import linear_model\n",
    "reg = linear_model.LinearRegression(fit_intercept=True)\n",
    "import pandas as pd\n",
    "\n",
    "from scipy import signal\n",
    "\n",
    "\n",
    "def get_doubling_time_via_regression(in_array):\n",
    "    ''' Use a linear regression to approximate the doubling rate\n",
    "\n",
    "        Parameters:\n",
    "        ----------\n",
    "        in_array : pandas.series\n",
    "\n",
    "        Returns:\n",
    "        ----------\n",
    "        Doubling rate: double\n",
    "    '''\n",
    "\n",
    "    y = np.array(in_array)\n",
    "    X = np.arange(-1,2).reshape(-1, 1)\n",
    "\n",
    "    assert len(in_array)==3\n",
    "    reg.fit(X,y)     # fitting a curve for  3 points using sklearn(Linear regression)\n",
    "    intercept=reg.intercept_\n",
    "    slope=reg.coef_\n",
    "\n",
    "    return intercept/slope # this gives the doublin rate w.r.t those 3 points\n",
    "\n",
    "\n",
    "def savgol_filter(df_input,column='confirmed',window=5):\n",
    "    ''' Savgol Filter which can be used in groupby apply function (data structure kept)\n",
    "\n",
    "        parameters:\n",
    "        ----------\n",
    "        df_input : pandas.series\n",
    "        column : str\n",
    "        window : int\n",
    "            used data points to calculate the filter result\n",
    "\n",
    "        Returns:\n",
    "        ----------\n",
    "        df_result: pd.DataFrame\n",
    "            the index of the df_input has to be preserved in result\n",
    "    '''\n",
    "\n",
    "    degree=1\n",
    "    df_result=df_input\n",
    "\n",
    "    filter_in=df_input[column].fillna(0) # attention with the neutral element here\n",
    "\n",
    "    result=signal.savgol_filter(np.array(filter_in),\n",
    "                           window, # window size used for filtering\n",
    "                           1)\n",
    "    df_result[str(column+'_filtered')]=result\n",
    "    return df_result\n",
    "\n",
    "def rolling_reg(df_input,col='confirmed'):\n",
    "    ''' Rolling Regression to approximate the doubling time'\n",
    "\n",
    "        Parameters:\n",
    "        ----------\n",
    "        df_input: pd.DataFrame\n",
    "        col: str\n",
    "            defines the used column\n",
    "        Returns:\n",
    "        ----------\n",
    "        result: pd.DataFrame\n",
    "    '''\n",
    "    days_back=3\n",
    "    result=df_input[col].rolling(\n",
    "                window=days_back,\n",
    "                min_periods=days_back).apply(get_doubling_time_via_regression,raw=False)\n",
    "\n",
    "\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def calc_filtered_data(df_input,filter_on='confirmed'):\n",
    "    '''  Calculate savgol filter and return merged data frame\n",
    "\n",
    "        Parameters:\n",
    "        ----------\n",
    "        df_input: pd.DataFrame\n",
    "        filter_on: str\n",
    "            defines the used column\n",
    "        Returns:\n",
    "        ----------\n",
    "        df_output: pd.DataFrame\n",
    "            the result will be joined as a new column on the input data frame\n",
    "    '''\n",
    "\n",
    "    must_contain=set(['state','country',filter_on])\n",
    "    assert must_contain.issubset(set(df_input.columns)), ' Erro in calc_filtered_data not all columns in data frame'\n",
    "\n",
    "    df_output=df_input.copy() # we need a copy here otherwise the filter_on column will be overwritten\n",
    "\n",
    "    pd_filtered_result=df_output[['state','country',filter_on]].groupby(['state','country']).apply(savgol_filter)#.reset_index()\n",
    "\n",
    "    df_output=pd.merge(df_output,pd_filtered_result[[str(filter_on+'_filtered')]],left_index=True,right_index=True,how='left')\n",
    "    \n",
    "    return df_output.copy()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def calc_doubling_rate(df_input,filter_on='confirmed'):\n",
    "    ''' Calculate approximated doubling rate and return merged data frame\n",
    "\n",
    "        Parameters:\n",
    "        ----------\n",
    "        df_input: pd.DataFrame\n",
    "        filter_on: str\n",
    "            defines the used column\n",
    "        Returns:\n",
    "        ----------\n",
    "        df_output: pd.DataFrame\n",
    "            the result will be joined as a new column on the input data frame\n",
    "    '''\n",
    "\n",
    "    must_contain=set(['state','country',filter_on])\n",
    "    assert must_contain.issubset(set(df_input.columns)), ' Erro in calc_filtered_data not all columns in data frame'\n",
    "\n",
    "\n",
    "    pd_DR_result= df_input.groupby(['state','country']).apply(rolling_reg,filter_on).reset_index()\n",
    "\n",
    "    pd_DR_result=pd_DR_result.rename(columns={filter_on:filter_on+'_DR',\n",
    "                             'level_2':'index'})\n",
    "\n",
    "    #we do the merge on the index of our big table and on the index column after groupby\n",
    "    df_output=pd.merge(df_input,pd_DR_result[['index',str(filter_on+'_DR')]],left_index=True,right_on=['index'],how='left')\n",
    "    df_output=df_output.drop(columns=['index'])\n",
    "\n",
    "\n",
    "    return df_output\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    test_data_reg=np.array([2,4,6])\n",
    "    result=get_doubling_time_via_regression(test_data_reg)\n",
    "    print('the test slope is: '+str(result))\n",
    "\n",
    "    pd_relational_model=pd.read_csv('data/processed/COVID_relational_confirmed.csv',sep=';',parse_dates=[0])\n",
    "    pd_relational_model=pd_relational_model.sort_values('date',ascending=True).copy()\n",
    "\n",
    "    pd_filtered_data=calc_filtered_data(pd_relational_model)\n",
    "    \n",
    "    pd_doubling_rate_data=calc_doubling_rate(pd_filtered_data)\n",
    "    \n",
    "    pd_result_larg=calc_doubling_rate(pd_doubling_rate_data,'confirmed_filtered')\n",
    "\n",
    "\n",
    "    mask=pd_result_larg['confirmed']>100\n",
    "    \n",
    "    pd_result_larg['confirmed_filtered_DR']=pd_result_larg['confirmed_filtered_DR'].where(mask, other=np.NaN)\n",
    "    pd_result_larg.to_csv('data/processed/COVID_final_set.csv',sep=';',index=False)\n",
    "    print(pd_result_larg[pd_result_larg['country']=='India'].tail())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 Modeling SIR\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sohai\\anaconda3\\lib\\site-packages\\scipy\\integrate\\odepack.py:248: ODEintWarning: Excess work done on this call (perhaps wrong Dfun type). Run with full_output = 1 to get quantitative information.\n",
      "  warnings.warn(warning_msg, ODEintWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " SIR simulation for 100 countries accomplished\n"
     ]
    }
   ],
   "source": [
    "# %load src/models/train_model.py\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "\n",
    "from scipy import optimize\n",
    "from scipy import integrate\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "sns.set(style=\"darkgrid\")\n",
    "\n",
    "mpl.rcParams['figure.figsize'] = (16, 9)\n",
    "pd.set_option('display.max_rows', 500)\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "def model_sir():\n",
    "    df_pop=pd.read_csv('data/processed/world_population.csv',sep=\";\")\n",
    "\n",
    "    df_data=pd.read_csv('data/processed/COVID_full_flat_table.csv',sep=';')\n",
    "    df_data=df_data.iloc[60:,:] #removing first 50 days of covid spread as the data is inconsistent\n",
    "    df_data=df_data.drop(['Taiwan*'], axis= 1) # dropping taiwan as the data is inconsistent\n",
    "\n",
    "\n",
    "    df_data=df_data.reset_index()\n",
    "    df_data=df_data.drop(['index'], axis=1)\n",
    "    df_data=df_data.rename(columns={'level_0':'index'})\n",
    "\n",
    "\n",
    "    df= pd.DataFrame(df_data.loc[0])\n",
    "    df=df.reset_index()\n",
    "    df = df.iloc[1:]\n",
    "    country_list= list(df[df[0]>38]['index']) #finding countries with significant number of covid cases i.e,>38\n",
    "    country_list.insert(0, 'Date')\n",
    "\n",
    "    df_data=df_data[country_list] # confining data frame to that perticular countries\n",
    "\n",
    "\n",
    "\n",
    "    for each in country_list[1:]:\n",
    "        ydata = np.array(df_data[each])\n",
    "        t=np.arange(len(ydata))\n",
    "        N0= df_pop[df_pop['country']== each]['population']\n",
    "        I0=ydata[0]\n",
    "        S0 = N0-I0\n",
    "        R0=0\n",
    "        def SIR_model_t(SIR,t,beta,gamma):\n",
    "\n",
    "\n",
    "            ''' Simple SIR model\n",
    "        S: susceptible population (populatin that can be effected)\n",
    "        I: infected people (population already infected)\n",
    "        R: recovered people (population recovered from COVID)\n",
    "        beta:\n",
    "\n",
    "        overall condition is that the sum of changes (differnces) sum up to 0\n",
    "        dS+dI+dR=0\n",
    "        S+I+R= N (constant size of population)\n",
    "\n",
    "    '''\n",
    "            S,I,R=SIR\n",
    "            dS_dt=-beta*S*I/N0          #S*I is the\n",
    "            dI_dt=beta*S*I/N0-gamma*I\n",
    "            dR_dt=gamma*I\n",
    "            return dS_dt,dI_dt,dR_dt\n",
    "\n",
    "        def fit_odeint(t, beta, gamma):\n",
    "            '''\n",
    "    helper function for the integration\n",
    "    '''\n",
    "            return integrate.odeint(SIR_model_t, (S0, I0, R0), t, args=(beta, gamma))[:,1] # we only would like to get dI\n",
    "\n",
    "        popt, pcov = optimize.curve_fit(fit_odeint, t, ydata,maxfev=50000)\n",
    "        perr = np.sqrt(np.diag(pcov))\n",
    "        fitted = fit_odeint(t, *popt).reshape((-1,1))\n",
    "        df_data[each+'_SIR']= fitted\n",
    "    df_data.to_csv('data/processed/COVID_SIR_model.csv',sep=';',index=False)\n",
    "    print(' SIR simulation for 100 countries accomplished')\n",
    "\n",
    "\n",
    "    return df_data\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    model_sir()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6 visualization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sohai\\Videos\\Python\\ads_covid-20\n",
      "Running on http://127.0.0.1:8050/\n",
      "Running on http://127.0.0.1:8050/\n",
      "Running on http://127.0.0.1:8050/\n",
      "Running on http://127.0.0.1:8050/\n",
      "Running on http://127.0.0.1:8050/\n",
      "Running on http://127.0.0.1:8050/\n",
      "Running on http://127.0.0.1:8050/\n",
      "Running on http://127.0.0.1:8050/\n",
      "Running on http://127.0.0.1:8050/\n",
      "Debugger PIN: 716-321-720\n",
      "Debugger PIN: 716-321-720\n",
      "Debugger PIN: 716-321-720\n",
      "Debugger PIN: 716-321-720\n",
      "Debugger PIN: 716-321-720\n",
      "Debugger PIN: 716-321-720\n",
      "Debugger PIN: 716-321-720\n",
      "Debugger PIN: 716-321-720\n",
      "Debugger PIN: 716-321-720\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Tip: There are .env or .flaskenv files present. Do \"pip install python-dotenv\" to use them.\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app \"__main__\" (lazy loading)\n",
      " * Environment: production\n",
      "   WARNING: This is a development server. Do not use it in a production deployment.\n",
      "   Use a production WSGI server instead.\n",
      " * Debug mode: on\n"
     ]
    }
   ],
   "source": [
    "# %load src/visualization/visualize_SIR.py\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import dash\n",
    "dash.__version__\n",
    "import dash_core_components as dcc\n",
    "import dash_html_components as html\n",
    "from dash.dependencies import Input, Output,State\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "import os\n",
    "print(os.getcwd())\n",
    "df_input_large=pd.read_csv('data/processed/COVID_final_set.csv',sep=';')\n",
    "df_input_SIR=pd.read_csv('data/processed/COVID_SIR_model.csv',sep=';')\n",
    "\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "app = dash.Dash()\n",
    "\n",
    "colors = {\n",
    "    'background': '#111111',\n",
    "    'text': '#7FDBFF' }\n",
    "\n",
    "app.layout = html.Div([html.H1(children='Applied Data Science on COVID-20 data', style={'color':'red'}),\n",
    "\n",
    "    dcc.Markdown('''\n",
    "    The goal of the project is to track Coronavirus spread across countries as the general information available on the internet is not so relevant and informative and to have a deep dive into local development of the spread and predict the future spread.\n",
    "    This project has been tackled using CRISP-DM approach and major emphasis has been laid on automating the data gathering process, filtered and transformed the gathered data, using machine learning for calculating the doubling rate, developing a SIR Model for forecasting the future spread and finally deploying on a responsive dashboard\n",
    "\n",
    "    '''),\n",
    "\n",
    "    html.Div([dcc.Markdown('''\n",
    "    ## Select Multiple Country for visualization\n",
    "    ''', style={'color':'green'}),\n",
    "\n",
    "\n",
    "    dcc.Dropdown(\n",
    "        id='country_drop_down',\n",
    "        options=[ {'label': each,'value':each} for each in df_input_large['country'].unique()],\n",
    "        value=['US', 'Germany','Italy'], # which are pre-selected\n",
    "        multi=True\n",
    "    )], style={'width': '30%', 'display': 'inline-block','border':'2px black solid', 'borderRadius':5}),\n",
    "\n",
    "    html.Div([dcc.Markdown('''\n",
    "        ## Select Timeline of confirmed COVID-20 cases or the approximated doubling time\n",
    "        ''', style={'color':'green'}),\n",
    "\n",
    "\n",
    "    dcc.RadioItems(\n",
    "    id='doubling_time',\n",
    "    options=[\n",
    "        {'label': 'Timeline Confirmed ', 'value': 'confirmed'},\n",
    "        {'label': 'Timeline Confirmed Filtered', 'value': 'confirmed_filtered'},\n",
    "        {'label': 'Timeline Doubling Rate', 'value': 'confirmed_DR'},\n",
    "        {'label': 'Timeline Doubling Rate Filtered', 'value': 'confirmed_filtered_DR'},\n",
    "    ],\n",
    "    value='confirmed',\n",
    "\n",
    "    labelStyle={'display': 'inline-block'}\n",
    "    )],style={'width': '68%', 'float': 'right', 'display': 'inline-block','border':'2px black solid', 'borderRadius':5}),\n",
    "\n",
    "    dcc.Graph(figure=fig, id='main_window_slope'),\n",
    "\n",
    "\n",
    "    html.Div([html.H1(\n",
    "        children='SIR Simulation Curve',\n",
    "        style={\n",
    "            'textAlign': 'center',\n",
    "            'color': '#FFA37F'\n",
    "        }\n",
    "    )]),\n",
    "\n",
    "    html.Div([dcc.Markdown('''\n",
    "    ## Select Multiple Country for SIR modeling curve\n",
    "    ''', style={'color':'green'}),\n",
    "\n",
    "    dcc.Dropdown(\n",
    "        id='country_drop_SIR_down',\n",
    "        options=[ {'label': each,'value':each} for each in df_input_SIR.columns[1:101]],\n",
    "        value=['Australia', 'Brazil','India'], # which are pre-selected\n",
    "        multi=True\n",
    "    )], style={'display': 'inline-block','border':'2px black solid', 'borderRadius':5}),\n",
    "\n",
    "\n",
    "    dcc.Graph(figure=fig, id='main_SIR_slope'),\n",
    "\n",
    "\n",
    "     ], style={'padding':10})\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "@app.callback(\n",
    "    Output('main_window_slope', 'figure'),\n",
    "    [Input('country_drop_down', 'value'),\n",
    "    Input('doubling_time', 'value')])\n",
    "def update_figure(country_list,show_doubling):\n",
    "\n",
    "\n",
    "    if 'doubling_rate' in show_doubling:\n",
    "        my_yaxis={'type':\"log\",\n",
    "               'title':'Approximated doubling rate over 3 days (larger numbers are better #stayathome)'\n",
    "              }\n",
    "    else:\n",
    "        my_yaxis={'type':\"log\",\n",
    "                  'title':'Confirmed infected people (source johns hopkins csse, log-scale)'\n",
    "              }\n",
    "\n",
    "\n",
    "    traces = []\n",
    "    for each in country_list:\n",
    "\n",
    "        df_plot=df_input_large[df_input_large['country']==each]\n",
    "\n",
    "        if show_doubling=='doubling_rate_filtered':\n",
    "            df_plot=df_plot[['state','country','confirmed','confirmed_filtered','confirmed_DR','confirmed_filtered_DR','date']].groupby(['country','date']).agg(np.mean).reset_index()\n",
    "        else:\n",
    "            df_plot=df_plot[['state','country','confirmed','confirmed_filtered','confirmed_DR','confirmed_filtered_DR','date']].groupby(['country','date']).agg(np.sum).reset_index()\n",
    "       #print(show_doubling)\n",
    "\n",
    "\n",
    "        traces.append(dict(x=df_plot.date,\n",
    "                                y=df_plot[show_doubling],\n",
    "                                mode='markers+lines',\n",
    "                                marker={'size': 3, 'opacity': 0.5},\n",
    "                                line= {'width':2, 'opacity' :0.9,},\n",
    "                                name=each\n",
    "                        )\n",
    "                )\n",
    "\n",
    "    return {\n",
    "            'data': traces,\n",
    "            'layout': dict (\n",
    "                width=1280,\n",
    "                height=720,\n",
    "\n",
    "                xaxis={'title':'Timeline',\n",
    "                        'tickangle':-45,\n",
    "                        'nticks':20,\n",
    "                        'tickfont':dict(size=14,color=\"#7f7f7f\"),\n",
    "                      },\n",
    "                 hovermode='closest',\n",
    "\n",
    "                yaxis=my_yaxis,\n",
    "                plot_bgcolor=colors['background'],\n",
    "                paper_bgcolor= colors['background'],\n",
    "        )\n",
    "    }\n",
    "\n",
    "@app.callback(\n",
    "    Output('main_SIR_slope', 'figure'),\n",
    "    [Input('country_drop_SIR_down', 'value')])\n",
    "\n",
    "def update_figure(country_list):\n",
    "\n",
    "    traces = []\n",
    "\n",
    "    for each in country_list:\n",
    "\n",
    "\n",
    "\n",
    "        traces.append(dict(x=df_input_SIR.Date,\n",
    "                                y=df_input_SIR[each],\n",
    "                                mode='markers+lines',\n",
    "                                marker={'size': 3, 'opacity': 0.5},\n",
    "                                line= {'width':2, 'opacity' :0.9,},\n",
    "                                name=each\n",
    "                        )\n",
    "                )\n",
    "        traces.append(dict(x=df_input_SIR.Date,\n",
    "                                y=df_input_SIR[each+'_SIR'],\n",
    "                                mode='markers+lines',\n",
    "                                marker={'size': 3, 'opacity': 0.5},\n",
    "                                line= {'width':2, 'opacity' :0.9,},\n",
    "                                name=each+'_SIR'\n",
    "                        )\n",
    "                )\n",
    "\n",
    "    return {\n",
    "            'data': traces,\n",
    "            'layout': dict (\n",
    "                width=1280,\n",
    "                height=720,\n",
    "\n",
    "                xaxis={'title':'Timeline',\n",
    "                        'tickangle':-45,\n",
    "                        'nticks':20,\n",
    "                        'tickfont':dict(size=14,color=\"#7f7f7f\"),\n",
    "                      },\n",
    "                 hovermode='closest',\n",
    "\n",
    "                yaxis={'type':\"log\",\n",
    "               'title':'SIR prediction'\n",
    "              },plot_bgcolor=colors['background'],\n",
    "                paper_bgcolor= colors['background'],\n",
    "        )\n",
    "    }\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    app.run_server(debug=True, use_reloader=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
